{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0214c4-acaf-491d-8a11-8c2898cab68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/user_order_final_onesheet.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1119558-b8b8-40aa-b665-de0104863371",
   "metadata": {},
   "source": [
    "# gpt suggestions for user_order_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757c78d-960b-4b14-9a66-c4e3f2f85045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'created_at' to datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# 1. Payment Method Analysis\n",
    "payment_method_dist = df['payment_getway_id'].value_counts()\n",
    "success_rate_by_payment = df[df['is_error'] == 0]['payment_getway_id'].value_counts() / df['payment_getway_id'].value_counts()\n",
    "\n",
    "# 2. Order Success Analysis\n",
    "order_success_rate = df['is_error'].value_counts(normalize=True)\n",
    "success_rate_by_registration = df[df['is_error'] == 0]['is_user'].value_counts() / df['is_user'].value_counts()\n",
    "\n",
    "# 3. Customer Registration Analysis\n",
    "registered_vs_unregistered = df['is_user'].value_counts()\n",
    "repeat_order_rate = df[df['is_user'] == 1]['unique_name'].value_counts().mean()\n",
    "\n",
    "# 4. Time-based Analysis\n",
    "orders_over_time = df.set_index('created_at').resample('M').size()\n",
    "average_interval = df['interval'].mean()\n",
    "\n",
    "# 5. Segmentation Analysis\n",
    "# Apply the same RFM analysis as before, adjusting based on this dataset\n",
    "\n",
    "# 6. Error Analysis\n",
    "error_rate_by_payment = df[df['is_error'] == 1]['payment_getway_id'].value_counts() / df['payment_getway_id'].value_counts()\n",
    "error_rate_by_time = df.set_index('created_at').resample('H')['is_error'].mean()\n",
    "\n",
    "# Visualize or export the results as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b83c69-0d28-4d67-92b4-5d963e8ffa32",
   "metadata": {},
   "source": [
    "### Customer Segmentation using Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238790af-e54f-4af1-ac6c-2fed962abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select relevant features\n",
    "features = df[['interval', 'payment_getway_id', 'is_user', 'is_error']]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df_new['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_analysis = df_new.groupby('cluster').mean()\n",
    "print(\"Cluster Analysis:\\n\", cluster_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da347731-55c8-49f8-82d7-fc122ff82e4e",
   "metadata": {},
   "source": [
    "#### Customer Lifetime Value (CLV) Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3f4da-b393-4f3e-bf96-cda7ba17f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate total revenue for each customer\n",
    "df_new['revenue'] = df_new['interval'] * df_new['payment_getway_id']\n",
    "customer_revenue = df_new.groupby('unique_name')['revenue'].sum()\n",
    "\n",
    "# Use RFM metrics and additional features for prediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare the data\n",
    "X = df_new[['R_Score', 'F_Score', 'is_user', 'payment_getway_id']]\n",
    "y = customer_revenue\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict CLV\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"CLV Prediction:\\n\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17831f27-7a1b-492c-9991-1c56e09da8c5",
   "metadata": {},
   "source": [
    "### Churn Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d01fe3-2038-486c-8f37-b6744b8bcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define churn as customers who haven't ordered in a long time\n",
    "df_new['churn'] = (df_new['Recency'] > 90).astype(int)\n",
    "\n",
    "# Prepare the data\n",
    "X = df_new[['R_Score', 'F_Score', 'is_user', 'payment_getway_id']]\n",
    "y = df_new['churn']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict churn\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Churn Prediction:\\n\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7397cb9-7f06-4b44-8126-7733c5ba362a",
   "metadata": {},
   "source": [
    "### Basket Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbacb68-eddc-4e40-bbc8-8cb12744d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# One-hot encode the item purchases\n",
    "basket = df_new.groupby(['order_id', 'item_name'])['item_name'].count().unstack().fillna(0)\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "print(\"Association Rules:\\n\", rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1476acc-15cf-4af1-9e41-fa1cd8fe00e5",
   "metadata": {},
   "source": [
    "### Time Series Forecasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083abe72-bb9c-4187-81ce-305a60d6f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Resample orders over time\n",
    "orders_over_time = df_new.set_index('created_at').resample('D')['order_id'].count()\n",
    "\n",
    "# Fit the model\n",
    "model = ExponentialSmoothing(orders_over_time, trend='add', seasonal='add', seasonal_periods=12)\n",
    "fit = model.fit()\n",
    "\n",
    "# Forecast future orders\n",
    "forecast = fit.forecast(30)\n",
    "print(\"Order Forecast:\\n\", forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061d34e-a6ee-43c2-954e-0d677fb72f7d",
   "metadata": {},
   "source": [
    "### Cohort Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b111f2-23d1-448c-af21-0572f7f4feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['order_month'] = df_new['created_at'].dt.to_period('M')\n",
    "df_new['cohort'] = df_new.groupby('unique_name')['order_month'].transform('min')\n",
    "\n",
    "cohort_data = df_new.groupby(['cohort', 'order_month']).size().unstack().fillna(0)\n",
    "cohort_sizes = cohort_data.iloc[:, 0]\n",
    "retention_matrix = cohort_data.divide(cohort_sizes, axis=0)\n",
    "print(\"Cohort Analysis:\\n\", retention_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5367d95-ce77-4fe7-a70c-22b3658fc14f",
   "metadata": {},
   "source": [
    "### Cluster Visualization with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c192354-dafc-4549-a51e-107de7a3b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select relevant features\n",
    "features = df_new[['interval', 'payment_getway_id', 'is_user', 'is_error']]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e9a52-4ecf-4e90-8203-febf036619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['cluster'] = df_new['cluster']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21faad67-f5c5-458b-b735-e7d1181ad045",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['cluster'], cmap='viridis', alpha=0.6)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Customer Segments (PCA)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a540f5-341f-4e6d-8557-94db44591a99",
   "metadata": {},
   "source": [
    "### radar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e02c8-3609-47f2-a9b4-ea5f710874e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_averages = df_new.groupby('cluster').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036c650-2eae-4a5a-b2e6-bd48162894d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Function to plot radar chart\n",
    "def plot_radar_chart(data, categories, title):\n",
    "    N = len(categories)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        values = data.iloc[i].tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=f'Cluster {i}')\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Select relevant features for the radar chart\n",
    "radar_data = segment_averages[['interval', 'payment_getway_id', 'is_user', 'is_error']]\n",
    "radar_data = StandardScaler().fit_transform(radar_data)\n",
    "radar_data = pd.DataFrame(radar_data, columns=['interval', 'payment_getway_id', 'is_user', 'is_error'])\n",
    "\n",
    "plot_radar_chart(radar_data, radar_data.columns, 'Customer Segments Comparison')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f7445-d3d3-4674-9705-9e08ed4aeadc",
   "metadata": {},
   "source": [
    "### Complete Code for PCA Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588f5a5-20b7-4414-baa9-3ee0b089abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'path_to_your_file/user_order_final_onesheet.xlsx'\n",
    "df_new = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "# Convert necessary columns to appropriate data types\n",
    "df_new['created_at'] = pd.to_datetime(df_new['created_at'], errors='coerce')\n",
    "df_new['last_buy'] = pd.to_datetime(df_new['last_buy'], errors='coerce')\n",
    "\n",
    "# Select relevant features for clustering\n",
    "features = df_new[['interval', 'payment_getway_id', 'is_user', 'is_error']]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Perform KMeans clustering for demonstration\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df_new['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "pca_df['cluster'] = df_new['cluster']\n",
    "\n",
    "# Plot the PCA scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['cluster'], cmap='viridis', alpha=0.6)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Customer Segments (PCA)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
