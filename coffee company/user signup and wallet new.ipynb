{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e82a2b-b4d5-4315-9ac6-bbe4fd51ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdd331c-c5ca-4558-aa3b-5d737660cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_order = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/Result_7.xlsx')\n",
    "\n",
    "#user_cards = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/kx_users_cards.xlsx')\n",
    "# column_to_drop = ['created_at','updated_at','card_number']\n",
    "# user_cards.drop(columns=column_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2738f8e6-0e82-4fd3-bde1-b30b513d26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## merge with user_cards\n",
    "# user_order_cards = pd.merge(user_order, user_cards, on='user_id', how='left')\n",
    "# column_to_drop = ['id']\n",
    "# user_order_cards.drop(columns=column_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82fd2a4a-726e-4be0-9c88-b0c5e17cff38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasan\\AppData\\Local\\Temp\\ipykernel_7332\\2986992066.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stations2.rename(columns={\"id\":\"station_id\",  \"name\":\"station_name\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## add station name\n",
    "stations = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/kx_stations.xlsx' )\n",
    "stations2 = stations[['id','name']]\n",
    "stations2.rename(columns={\"id\":\"station_id\",  \"name\":\"station_name\"}, inplace=True)\n",
    "user_order_cards2 = pd.merge(user_order, stations2, on='station_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0bb2d5-212f-40f6-acb6-d702d3ec5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add item name\n",
    "## ino avaz kon. hamoon 2 ta table order_rows and items ro import kon va haminja merge kon\n",
    "items = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/order_item.xlsx' )\n",
    "\n",
    "user_order_cards3 = pd.merge(user_order_cards2, items, on='order_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11907508-35c6-40ec-835d-bf448c790e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add is_user, year and mont, hour and uniqe_name to DF\n",
    "\n",
    "# Convert the created_at column to datetime\n",
    "user_order_cards3['created_at'] = pd.to_datetime(user_order_cards3['created_at'])\n",
    "\n",
    "# Extract hour and minute and format as \"HH:MM\"\n",
    "user_order_cards3['hour_minute'] = user_order_cards3['created_at'].dt.strftime('%H:%M')\n",
    "# Extract year and month and format as \"YYYY-MM\"\n",
    "user_order_cards3['year_month'] = user_order_cards3['created_at'].dt.strftime('%Y-%m')\n",
    "# year_month_day\n",
    "user_order_cards3['year_month_day'] = user_order_cards3['created_at'].dt.strftime('%Y-%m-%d')\n",
    "# week day\n",
    "user_order_cards3['weekday'] = user_order_cards3['created_at'].dt.strftime('%A')\n",
    "\n",
    "\n",
    "## set not user for user_id = 0\n",
    "user_order_cards3.loc[user_order_cards3['user_id'] == 0, 'username'] = 'not user'\n",
    "\n",
    "\n",
    "## set is_user 1/0\n",
    "user_order_cards3['is_user']=0\n",
    "user_order_cards3.loc[user_order_cards3['user_id'] != 0, 'is_user'] = 1\n",
    "\n",
    "## unique name for handling users who have several cards and users who did not register\n",
    "user_order_cards3['unique_name'] = user_order_cards3['username']\n",
    "user_order_cards3.loc[user_order_cards3['username'] == 'not user', 'unique_name'] = user_order_cards3['card_number']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e6304d-94d0-4381-8ac5-6eb149fdde88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasan\\AppData\\Local\\Temp\\ipykernel_7332\\3259060630.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_order_cards3.admin.fillna(value=0,inplace=True)\n",
      "C:\\Users\\Sasan\\AppData\\Local\\Temp\\ipykernel_7332\\3259060630.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_order_cards3.merchant.fillna(value=0,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## fill nan admin and merchant for user_id = 0\n",
    "user_order_cards3.admin.fillna(value=0,inplace=True)\n",
    "user_order_cards3.merchant.fillna(value=0,inplace=True)\n",
    "\n",
    "\n",
    "##filter merchant and admin\n",
    "user_order_cards3 = user_order_cards3[(user_order_cards3['merchant']==0) & (user_order_cards3['admin']==0 )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d4a5506-53d7-4b0f-9773-61deefa71291",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add frequency analysis columns : previous purchase - interval\n",
    "\n",
    "# Convert created_at to datetime\n",
    "user_order_cards3['created_at'] = pd.to_datetime(user_order_cards3['created_at'])\n",
    "\n",
    "# Sort by unique_name and created_at\n",
    "user_order_cards3 = user_order_cards3.sort_values(by=['unique_name', 'created_at'])\n",
    "\n",
    "# Calculate the time difference between consecutive purchases\n",
    "user_order_cards3['previous_purchase'] = user_order_cards3.groupby('unique_name')['created_at'].shift(1)\n",
    "user_order_cards3['interval2'] = (user_order_cards3['created_at'] - user_order_cards3['previous_purchase']).dt.total_seconds() / (60*60*24)  # Convert to days\n",
    "\n",
    "## set interval when there is sonly 2:50 distance between orders and is_error=1\n",
    "user_order_cards3['interval'] = user_order_cards3['interval2']\n",
    "user_order_cards3.loc[user_order_cards3['interval2']<0.002, 'interval']= np.NaN\n",
    "user_order_cards3.loc[user_order_cards3['is_error']==1, 'interval']= np.NaN\n",
    "\n",
    "user_order_cards3 = user_order_cards3.drop(columns=['interval2'])\n",
    "\n",
    "# Compute the average interval for each customer\n",
    "frequency_analysis = user_order_cards3.groupby('unique_name').agg({'interval': 'mean'}).reset_index()\n",
    "frequency_analysis.rename(columns={'interval': 'average_interval_days'}, inplace=True)\n",
    "\n",
    "\n",
    "user_order_cards3.to_excel('user_order_final.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e30dbb04-dcdd-4cae-b8f1-88b4ffb5ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by on unique name\n",
    "\n",
    "###is_error =1 remove for group by\n",
    "## filter df\n",
    "user_order_cards3 = user_order_cards3[user_order_cards3['is_error']==0]\n",
    "## copy for group by on station name\n",
    "user_order_cards4 = user_order_cards3.copy()\n",
    "\n",
    "# Your initial aggregation\n",
    "\n",
    "rfm = user_order_cards3.groupby('unique_name').aggregate({'price_total': 'count', 'year_month_day': ['min', 'max']})\n",
    "rfm.columns = ['buy_count', 'date_min', 'date_max']\n",
    "rfm = pd.DataFrame(rfm).reset_index()\n",
    "\n",
    "# Group by 'unique_name', 'item_name', and 'station_name' and count occurrences\n",
    "grouped_data = user_order_cards3.groupby(['unique_name', 'item_name', 'station_name']).size().reset_index(name='count')\n",
    "\n",
    "# Identify the most frequent item_name for each unique_name\n",
    "favorite_items = grouped_data.loc[grouped_data.groupby('unique_name')['count'].idxmax()][['unique_name', 'item_name', 'count']]\n",
    "\n",
    "# Identify the most frequent station_name for each unique_name\n",
    "favorite_stations = grouped_data.loc[grouped_data.groupby('unique_name')['count'].idxmax()][['unique_name', 'station_name', 'count']]\n",
    "\n",
    "# Merge the favorite items and stations into a single DataFrame\n",
    "favorite_items_and_stations = favorite_items.merge(favorite_stations, on=['unique_name', 'count'])\n",
    "\n",
    "# Merge with rfm2 DataFrame\n",
    "merged_df = rfm.merge(favorite_items_and_stations, on='unique_name', how='left')\n",
    "\n",
    "# Merge with merged_df with frequency_analysis\n",
    "merged_dff = merged_df.merge(frequency_analysis, on='unique_name', how='left')\n",
    "\n",
    "# Create new columns for payment_getway_id counts\n",
    "payment_counts = user_order_cards3.groupby(['unique_name', 'payment_getway_id']).size().unstack(fill_value=0).reset_index()\n",
    "payment_counts.columns = ['unique_name', 'count_1', 'count_2', 'count_3']\n",
    "\n",
    "# Merge with merged_df\n",
    "rfm_final = merged_dff.merge(payment_counts, on='unique_name', how='left')\n",
    "\n",
    "rfm_final.to_excel('rfm.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a551c65-c9d6-4a10-898b-5e13226a018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add station frequency analysis columns: previous purchase - interval\n",
    "\n",
    "\n",
    "# Sort by unique_name and created_at\n",
    "\n",
    "user_order_cards4 = user_order_cards4.sort_values(by=['station_name', 'created_at'])\n",
    "\n",
    "# Calculate the time difference between consecutive purchases\n",
    "user_order_cards4['previous_purchase'] = user_order_cards4.groupby('station_name')['created_at'].shift(1)\n",
    "user_order_cards4['interval2'] = (user_order_cards4['created_at'] - user_order_cards4['previous_purchase']).dt.total_seconds() / (60*60*24)  # Convert to days\n",
    "\n",
    "## set interval when there is sonly 2:50 distance between orders\n",
    "user_order_cards4['interval'] = user_order_cards4['interval2']\n",
    "user_order_cards4.loc[user_order_cards4['interval2']<0.002, 'interval']= np.NaN\n",
    "user_order_cards4 = user_order_cards4.drop(columns=['interval2'])\n",
    "\n",
    "# Compute the average interval for each customer\n",
    "frequency_analysis_station = user_order_cards4.groupby('station_name').agg({'interval': 'mean'}).reset_index()\n",
    "frequency_analysis_station.rename(columns={'interval': 'average_interval_days'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c23f3f44-ac08-4822-93a6-b3107ae201ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by on unique name\n",
    "\n",
    "\n",
    "# Your initial aggregation\n",
    "srfm = user_order_cards4.groupby('station_name').aggregate({'price_total': 'count', 'year_month_day': ['min', 'max']})\n",
    "srfm.columns = ['buy_count', 'date_min', 'date_max']\n",
    "srfm = pd.DataFrame(srfm).reset_index()\n",
    "\n",
    "\n",
    "# Merge with merged_df with frequency_analysis\n",
    "smerged_df = srfm.merge(frequency_analysis_station, on='station_name', how='left')\n",
    "\n",
    "# Create new columns for payment_getway_id counts\n",
    "payment_counts_station = user_order_cards4.groupby(['station_name', 'payment_getway_id']).size().unstack(fill_value=0).reset_index()\n",
    "payment_counts_station.columns = ['station_name', 'count_1', 'count_2', 'count_3']\n",
    "\n",
    "# Merge with merged_df\n",
    "rfm_station = smerged_df.merge(payment_counts_station, on='station_name', how='left')\n",
    "\n",
    "rfm_station.to_excel('rfm_station.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3df674-965d-429b-b6b6-0bd8fd4b707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## report to aliz : alarm!!\n",
    "### check for card_numbers which have more than 1 user_id(most are firsly 0 and then creat account)\n",
    "result = user_order_cards3.groupby('card_number')['user_id'].nunique()\n",
    "\n",
    "# Filter out card numbers that refer to more than one unique user_id\n",
    "unique_card_numbers = result[result > 1]\n",
    "unique_card_numbers.to_excel('0cardnum_morethan1userid.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b8ca0-44c6-430c-b119-3f83fb340f76",
   "metadata": {},
   "source": [
    "## add is active "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de19a013-ea6a-412f-8f47-0319fdb8c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add is active \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "rfmc = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/rfm_complete.xlsx') \n",
    "rfmsc = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/rfm_station_complete.xlsx') \n",
    "user_order = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/Book1.xlsx') \n",
    "\n",
    "is_active = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/isactive_stations.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3143f1cb-94c9-4eba-8624-5933da0bc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmc2 = rfmc.merge(is_active, on='station_name', how='left')\n",
    "rfmsc2 = rfmsc.merge(is_active, on='station_name', how='left')\n",
    "user_order2 = user_order.merge(is_active, on='station_name', how='left')\n",
    "rfmc2.to_excel('rfm_complete2.xlsx')\n",
    "rfmsc2.to_excel('rfm_station_complete2.xlsx')\n",
    "user_order2.to_excel('Book12.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d895d563-e168-4bfd-84ec-2e0a9478e7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19485f33-5a2a-4756-9951-9b2aa81e6de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e863da-4784-479c-8507-d375ed0460fa",
   "metadata": {},
   "source": [
    "### finding items of high value customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "030fdd56-958f-4028-bad8-01a701a25722",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmc = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/rfm_complete.xlsx') \n",
    "rfmsc = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/rfm_station_complete.xlsx') \n",
    "user_order = pd.read_excel(r'C:\\Users\\Sasan\\Desktop\\tasks\\user signup and wallet - new/user_order_final_isactive.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84dd8267-84f6-4700-80d7-2880db7844d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'order_id', 'station_id', 'user_id', 'payment_getway_id',\n",
       "       'price_total', 'card_number', 'created_at', 'merchant', 'admin',\n",
       "       'username', 'is_reseller', 'is_error', 'mobile', 'station_name',\n",
       "       'item_id', 'item_name', 'hour_minute', 'year_month', 'year_month_day',\n",
       "       'weekday', 'is_user', 'unique_name', 'previous_purchase', 'interval',\n",
       "       'hour', 'is_active', 'RFM_Score', 'Segment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_rfmc = rfmc [['unique_name','RFM_Score','Segment']]\n",
    "user_order2 = user_order.merge(selected_rfmc, on='unique_name', how='left')\n",
    "selected_rfmsc = rfmsc [['station_name','RFM_Score_station','Segment_station']]\n",
    "user_order3 = user_order2.merge(selected_rfmsc, on='station_name', how='left')\n",
    "\n",
    "user_order3.to_excel('user_order_complete.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8068c02-2c29-4f28-a489-7398abc1013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_order3.to_excel('user_order_complete.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
